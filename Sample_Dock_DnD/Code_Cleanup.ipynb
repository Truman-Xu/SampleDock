{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1: Clean up the code and modulize\n",
    "1. Simplified VAE util\n",
    "2. Sample and dock mol gen Script\n",
    "3. Docking bash script\n",
    "4. Score Processing script\n",
    "5. Fingerprint script\n",
    "6. Clustering script\n",
    "7. Wrapper bash script <br>\n",
    "Stage 2: Performance improvement\n",
    "Maybe compile most of the functions and write and compile the wrapper in C++?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Core Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named mol_tree",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7ebc91fec96d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmol_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMolTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnnutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjtnn_enc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJTNNEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named mol_tree"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mol_tree import Vocab, MolTree\n",
    "from nnutils import create_var, flatten_tensor, avg_pool\n",
    "from jtnn_enc import JTNNEncoder\n",
    "from jtnn_dec import JTNNDecoder\n",
    "from mpn import MPN\n",
    "from jtmpn import JTMPN\n",
    "from datautils import tensorize\n",
    "from fast_jtnn import *\n",
    "\n",
    "from chemutils import enum_assemble, set_atommap, copy_edit_mol, attach_mols\n",
    "import rdkit\n",
    "import rdkit.Chem as Chem\n",
    "import copy, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Stock JTNN VAE Model\n",
    "vocab = [x.strip(\"\\r\\n \") for x in open('../data/moses/vocab.txt')] \n",
    "vocab = Vocab(vocab)\n",
    "nsample = 100\n",
    "latent_size = 56\n",
    "depthT = 20\n",
    "depthG = 3\n",
    "hidden_size = 450\n",
    "model_loc = '../fast_molvae/moses-h450z56/model.iter-400000'\n",
    "jtnn = JTNNVAE(vocab, hidden_size, latent_size, depthT, depthG)\n",
    "jtnn.load_state_dict(torch.load(model_loc, map_location=torch.device('cpu')))\n",
    "\n",
    "#### Copied from jtnn.nnutils\n",
    "def create_var(tensor, requires_grad=None):\n",
    "    if requires_grad is None:\n",
    "        return Variable(tensor)\n",
    "    else:\n",
    "        return Variable(tensor, requires_grad=requires_grad)\n",
    "       \n",
    "#### Random latent vector sampling based on mean and log var        \n",
    "def z_vecs(x_mean, x_log_var):\n",
    "    \n",
    "    epsilon = create_var(torch.randn_like(x_mean))\n",
    "    z_vecs = x_mean + torch.exp(x_log_var / 2) * epsilon\n",
    "    return z_vecs\n",
    "\n",
    "def encode_from_smiles_xs(self, smiles):\n",
    "        tree_batch = [MolTree(smiles)]\n",
    "        _, jtenc_holder, mpn_holder = tensorize(tree_batch, self.vocab, assm=False)\n",
    "        tree_vecs, _, mol_vecs = self.encode(jtenc_holder, mpn_holder)\n",
    "        return tree_vecs, mol_vecs\n",
    "\n",
    "#### Takes one smiles and generate numbers of designs\n",
    "def smiles_gen(smiles,ndesigns):\n",
    "    ## Convert smiles to one-hot encoding (modified function from the original code)\n",
    "    x_tree, x_mol = jtnn.encode_from_smiles_xs(smiles)\n",
    "    ## Convert one-hots to mean and log var. Following Mueller et al.\n",
    "    tree_mean = jtnn.T_mean(x_tree)\n",
    "    tree_log_var = -torch.abs(jtnn.T_var(x_tree)) \n",
    "    mol_mean = jtnn.G_mean(x_mol)\n",
    "    mol_log_var = -torch.abs(jtnn.G_var(x_mol))\n",
    "\n",
    "    smiles_list = []\n",
    "    for i in range(ndesigns):\n",
    "        ## generate latent vectors (stochastic)\n",
    "        z_tree = z_vecs(tree_mean, tree_log_var)\n",
    "        z_mol = z_vecs(mol_mean, mol_log_var)\n",
    "        ## decode back to smiles\n",
    "        smilesout = jtnn.decode(z_tree,z_mol,False)\n",
    "        ## Check if the smiles already exists\n",
    "        if smilesout not in smiles_list:\n",
    "            smiles_list.append(smilesout)    \n",
    "    return smiles_list\n",
    "\n",
    "#### Generate and save .sdf from smiles for each design cycle\n",
    "def smiles_to_sdfile(smiles_list):\n",
    "    for i, x in enumerate(smiles_list):\n",
    "        name = 'design_'+str(i)\n",
    "        output = '%s/design/'%(directory)+name+'.sd'\n",
    "        m2 = Chem.MolFromSmiles(x)\n",
    "        AllChem.Compute2DCoords(m2)\n",
    "        m2.SetProp(\"_Name\", name)\n",
    "        m3 = Chem.AddHs(m2)\n",
    "        AllChem.EmbedMolecule(m3,AllChem.ETKDG())\n",
    "        w = Chem.SDWriter(output)\n",
    "        w.write(m3)\n",
    "        w.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
